{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel, MobileViTForSemanticSegmentation\n",
    "\n",
    "from models.mobilevit import MobileVIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/mmenendezg/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token $HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileViTForSemanticSegmentation were not initialized from the model checkpoint at apple/deeplabv3-mobilevit-xx-small and are newly initialized because the shapes did not match:\n",
      "- segmentation_head.classifier.convolution.weight: found shape torch.Size([21, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated\n",
      "- segmentation_head.classifier.convolution.bias: found shape torch.Size([21]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mobilevit_model = MobileVIT.load_from_checkpoint(\n",
    "    \"../models/FluorescentMobileVIT/epoch=59-step=6120.ckpt\", hparams_file=\"../config/fluorescent_mobilevit_hps.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5713718d58b423b968b41cdc6c6d53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/7.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mmenendezg/mobilevit-fluorescent-neuronal-cells/commit/21e1d453e032dc0d5ba8aec0def43b5a71fd3004', commit_message='Upload MobileViTForSemanticSegmentation', commit_description='', oid='21e1d453e032dc0d5ba8aec0def43b5a71fd3004', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilevit_model.model.push_to_hub(\"mobilevit-fluorescent-neuronal-cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileViTForSemanticSegmentation(\n",
       "  (mobilevit): MobileViTModel(\n",
       "    (conv_stem): MobileViTConvLayer(\n",
       "      (convolution): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (normalization): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): SiLUActivation()\n",
       "    )\n",
       "    (encoder): MobileViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): MobileViTMobileNetLayer(\n",
       "          (layer): ModuleList(\n",
       "            (0): MobileViTInvertedResidual(\n",
       "              (expand_1x1): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): SiLUActivation()\n",
       "              )\n",
       "              (conv_3x3): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                (normalization): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): SiLUActivation()\n",
       "              )\n",
       "              (reduce_1x1): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): MobileViTMobileNetLayer(\n",
       "          (layer): ModuleList(\n",
       "            (0): MobileViTInvertedResidual(\n",
       "              (expand_1x1): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): SiLUActivation()\n",
       "              )\n",
       "              (conv_3x3): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "                (normalization): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): SiLUActivation()\n",
       "              )\n",
       "              (reduce_1x1): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1-2): 2 x MobileViTInvertedResidual(\n",
       "              (expand_1x1): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): SiLUActivation()\n",
       "              )\n",
       "              (conv_3x3): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "                (normalization): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): SiLUActivation()\n",
       "              )\n",
       "              (reduce_1x1): MobileViTConvLayer(\n",
       "                (convolution): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (normalization): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): MobileViTLayer(\n",
       "          (downsampling_layer): MobileViTInvertedResidual(\n",
       "            (expand_1x1): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (normalization): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): SiLUActivation()\n",
       "            )\n",
       "            (conv_3x3): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "              (normalization): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): SiLUActivation()\n",
       "            )\n",
       "            (reduce_1x1): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (normalization): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (conv_kxk): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "          (conv_1x1): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (transformer): MobileViTTransformer(\n",
       "            (layer): ModuleList(\n",
       "              (0-1): 2 x MobileViTTransformerLayer(\n",
       "                (attention): MobileViTAttention(\n",
       "                  (attention): MobileViTSelfAttention(\n",
       "                    (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                    (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                    (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): MobileViTSelfOutput(\n",
       "                    (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                    (dropout): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): MobileViTIntermediate(\n",
       "                  (dense): Linear(in_features=64, out_features=128, bias=True)\n",
       "                  (intermediate_act_fn): SiLUActivation()\n",
       "                )\n",
       "                (output): MobileViTOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (layernorm_before): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                (layernorm_after): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (conv_projection): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "          (fusion): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "        )\n",
       "        (3): MobileViTLayer(\n",
       "          (downsampling_layer): MobileViTInvertedResidual(\n",
       "            (expand_1x1): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): SiLUActivation()\n",
       "            )\n",
       "            (conv_3x3): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (normalization): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): SiLUActivation()\n",
       "            )\n",
       "            (reduce_1x1): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (conv_kxk): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "          (conv_1x1): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (transformer): MobileViTTransformer(\n",
       "            (layer): ModuleList(\n",
       "              (0-3): 4 x MobileViTTransformerLayer(\n",
       "                (attention): MobileViTAttention(\n",
       "                  (attention): MobileViTSelfAttention(\n",
       "                    (query): Linear(in_features=80, out_features=80, bias=True)\n",
       "                    (key): Linear(in_features=80, out_features=80, bias=True)\n",
       "                    (value): Linear(in_features=80, out_features=80, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): MobileViTSelfOutput(\n",
       "                    (dense): Linear(in_features=80, out_features=80, bias=True)\n",
       "                    (dropout): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): MobileViTIntermediate(\n",
       "                  (dense): Linear(in_features=80, out_features=160, bias=True)\n",
       "                  (intermediate_act_fn): SiLUActivation()\n",
       "                )\n",
       "                (output): MobileViTOutput(\n",
       "                  (dense): Linear(in_features=160, out_features=80, bias=True)\n",
       "                  (dropout): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (layernorm_before): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "                (layernorm_after): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (layernorm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "          (conv_projection): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "          (fusion): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "        )\n",
       "        (4): MobileViTLayer(\n",
       "          (downsampling_layer): MobileViTInvertedResidual(\n",
       "            (expand_1x1): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): SiLUActivation()\n",
       "            )\n",
       "            (conv_3x3): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (activation): SiLUActivation()\n",
       "            )\n",
       "            (reduce_1x1): MobileViTConvLayer(\n",
       "              (convolution): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (normalization): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (conv_kxk): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "          (conv_1x1): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(80, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (transformer): MobileViTTransformer(\n",
       "            (layer): ModuleList(\n",
       "              (0-2): 3 x MobileViTTransformerLayer(\n",
       "                (attention): MobileViTAttention(\n",
       "                  (attention): MobileViTSelfAttention(\n",
       "                    (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "                    (key): Linear(in_features=96, out_features=96, bias=True)\n",
       "                    (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): MobileViTSelfOutput(\n",
       "                    (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "                    (dropout): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (intermediate): MobileViTIntermediate(\n",
       "                  (dense): Linear(in_features=96, out_features=192, bias=True)\n",
       "                  (intermediate_act_fn): SiLUActivation()\n",
       "                )\n",
       "                (output): MobileViTOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (layernorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (conv_projection): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "          (fusion): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(160, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLUActivation()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): MobileViTDeepLabV3(\n",
       "    (aspp): MobileViTASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): MobileViTConvLayer(\n",
       "          (convolution): Conv2d(80, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (1): MobileViTConvLayer(\n",
       "          (convolution): Conv2d(80, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (2): MobileViTConvLayer(\n",
       "          (convolution): Conv2d(80, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (3): MobileViTConvLayer(\n",
       "          (convolution): Conv2d(80, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
       "          (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (4): MobileViTASPPPooling(\n",
       "          (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_1x1): MobileViTConvLayer(\n",
       "            (convolution): Conv2d(80, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (project): MobileViTConvLayer(\n",
       "        (convolution): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classifier): MobileViTConvLayer(\n",
       "      (convolution): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilevit_model = MobileViTForSemanticSegmentation.from_pretrained(\n",
    "    \"mmenendezg/mobilevit-fluorescent-neuronal-cells\"\n",
    ")\n",
    "mobilevit_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
